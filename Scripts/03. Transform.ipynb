{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe8a3338-010d-4a01-98a4-2e5536fe6c02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create dim_date\n",
    "\n",
    "from pyspark.sql.functions import explode, sequence, to_date\n",
    "\n",
    "beginDate = '1900-01-01'\n",
    "endDate = '2050-12-31'\n",
    "\n",
    "spark.sql(f\"SELECT explode(sequence(to_date('{beginDate}'), to_date('{endDate}'), interval 1 day)) as date_key\") \\\n",
    "    .createOrReplaceTempView('tmp_dates')\n",
    "\n",
    "spark.sql(\" \\\n",
    "    CREATE TABLE dim_dates \\\n",
    "    USING DELTA LOCATION '/delta/gold_dim_dates' \\\n",
    "    SELECT \\\n",
    "        date_key, \\\n",
    "        year(date_key) AS year, \\\n",
    "        month(date_key) AS month, \\\n",
    "        day(date_key) AS day, \\\n",
    "        dayofweek(date_key) AS day_of_week, \\\n",
    "        quarter(date_key) AS quarter \\\n",
    "    FROM tmp_dates \\\n",
    "    ORDER by date_key;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9328d83b-78c1-431d-a093-e2dc7ac17839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Payments\n",
    "\n",
    "bronze_payments = spark.table(\"bronze_payments\")\n",
    "bronze_payments = bronze_payments \\\n",
    "    .withColumnRenamed(\"payment_id\", \"payment_key\") \\\n",
    "    .withColumnRenamed(\"rider_id\", \"rider_key\") \\\n",
    "\n",
    "bronze_payments.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"fact_payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed2a3337-5a4c-4fea-8e5a-64e1a9de8a70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Riders\n",
    "\n",
    "bronze_riders = spark.table(\"bronze_riders\")\n",
    "bronze_riders = bronze_riders \\\n",
    "    .withColumnRenamed(\"rider_id\", \"rider_key\") \\\n",
    "    .withColumnRenamed(\"account_date_start\", \"account_date_start_key\") \\\n",
    "    .withColumnRenamed(\"account_date_end\", \"account_date_end_key\") \\\n",
    "\n",
    "bronze_riders.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"dim_riders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "745e4d0a-e265-4fb5-9649-59ea1fd362c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Station\n",
    "\n",
    "bronze_stations = spark.table(\"bronze_stations\")\n",
    "bronze_stations = bronze_stations \\\n",
    "    .withColumnRenamed(\"station_id\", \"station_key\")\n",
    "\n",
    "bronze_stations.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"dim_stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b96a1909-20ab-4a50-87b0-2828a3c961a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Trips\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "riders = spark.table('dim_riders')\n",
    "bronze_trips = spark.table(\"bronze_trips\")\n",
    "\n",
    "trips = bronze_trips.join(riders, riders.rider_key == bronze_trips.rider_id) \\\n",
    "    .withColumnRenamed('trip_id', 'trip_key') \\\n",
    "    .withColumnRenamed('rider_id', 'rider_key') \\\n",
    "    .withColumnRenamed('start_station_id', 'start_station_key') \\\n",
    "    .withColumnRenamed('end_station_id', 'end_station_key') \\\n",
    "    .withColumn('start_date_key', bronze_trips.started_at[0:11].cast(\"date\")) \\\n",
    "    .withColumn('start_time', bronze_trips.started_at[12:20]) \\\n",
    "    .withColumn('end_date_key', bronze_trips.ended_at[0:11].cast(\"date\")) \\\n",
    "    .withColumn('end_time', bronze_trips.ended_at[12:20]) \\\n",
    "    .withColumn('ride_duration', (bronze_trips.ended_at.cast(\"long\") - bronze_trips.started_at.cast(\"long\"))) \\\n",
    "    .withColumn('rider_age', floor(months_between(current_date(), riders.birthdate)/12)) \\\n",
    "    .select('trip_key', riders.rider_key, 'start_station_key', 'end_station_key', 'start_date_key', 'start_time', 'end_date_key', 'end_time', 'ride_duration', 'rideable_type', 'rider_age')\n",
    "\n",
    "\n",
    "trips.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"fact_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5b44b72-e58d-408a-b305-c01aed8163f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2178772426446544,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03. Transform",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
